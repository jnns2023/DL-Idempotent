{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amgcsa\\miniconda3\\envs\\KTHenv\\Lib\\site-packages\\ignite\\handlers\\checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from idem_net_mnist import IdemNetMnist\n",
    "from idem_net_celeba import IdemNetCeleba\n",
    "from data_loader import load_MNIST, load_CelebA\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_utils import plot_generation\n",
    "from ignite.metrics import FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_id = \"mnist20241113-115000\"\n",
    "epoch_num = \"final.pth\"\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "checkpoint_path = f\"checkpoints/{run_id}/{epoch_num}\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"celeba\" in run_id:\n",
    "  model = IdemNetCeleba(3) # IdemNetMnist()\n",
    "else:\n",
    "  model = IdemNetMnist()\n",
    "\n",
    "state_dict = torch.load(checkpoint_path, weights_only=True, map_location=device)\n",
    "# state_dict = state_dict[\"model_state_dict\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the FID metric and feature extractor (InceptionV3)\n",
    "fid_metric = FID(device=device)\n",
    "\n",
    "# Get a batch of real images for FID score calculation\n",
    "data_loader, test_loader = load_MNIST(batch_size=256)\n",
    "test_imgs, _ = next(iter(data_loader))\n",
    "test_imgs = test_imgs.to(device)\n",
    "\n",
    "# Generate fake images using the trained model\n",
    "z_gen = torch.randn_like(test_imgs)  # Batch of noise to generate images from\n",
    "with torch.no_grad():\n",
    "    fake_images = model(z_gen)\n",
    "\n",
    "# Normalize to [0, 1]\n",
    "real_images = (test_imgs - test_imgs.min()) / (test_imgs.max() - test_imgs.min())\n",
    "fake_images = (fake_images - fake_images.min()) / (fake_images.max() - fake_images.min())\n",
    "\n",
    "# Convert single-channel images to three channels\n",
    "real_images = real_images.repeat(1, 3, 1, 1)\n",
    "fake_images = fake_images.repeat(1, 3, 1, 1)\n",
    "\n",
    "# Resize images to 299x299 for InceptionV3\n",
    "real_images = F.interpolate(real_images, size=(299, 299), mode=\"bilinear\", align_corners=False)\n",
    "fake_images = F.interpolate(fake_images, size=(299, 299), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "# Update FID metric\n",
    "fid_metric.reset()\n",
    "fid_metric.update((real_images, fake_images))\n",
    "fid_score = fid_metric.compute()\n",
    "\n",
    "print(f\"FID Score on the last images: {fid_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KTHenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
